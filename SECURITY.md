# Security Policy

## Supported Versions

We currently support the latest stable release series.

| Version | Supported          |
| ------- | ------------------ |
| 5.8.x   | :white_check_mark: |
| < 5.8   | :x:                |

## Reporting a Vulnerability

If you discover a security vulnerability within Glupe, please send an e-mail to the project maintainer at **alonsovm443@outlook.com**.

Please include:
*   A description of the vulnerability.
*   Steps to reproduce the issue.
*   Any relevant code snippets or `.glp` files.

We aim to acknowledge receipt of your vulnerability report within 48 hours and will send you regular updates about our progress.

## AI Safety & Code Execution

Glupe is a meta-compiler that uses Large Language Models (LLMs) to generate executable code.

*   **Execution Risk**: Code generated by Glupe runs with the same privileges as the user running the `glupe` command.
*   **Review**: Users are strongly advised to review the generated source code (e.g., `.cpp`, `.py`) before execution, especially when using the `-run` flag.
*   **Isolation**: While Semantic Containers (`$${...}$$`) provide logical isolation within the source file, they do not provide runtime sandboxing. Malicious prompts could theoretically generate malicious code if the LLM is jailbroken.

## Infrastructure & Privacy

*   **API Keys**: When using cloud providers (OpenAI, Google), your API keys are stored locally in `config.json`. Ensure this file is kept secure and not committed to public repositories.
*   **Local Models**: Using local models (Ollama) via the `-local` flag is recommended for privacy-sensitive code generation, as no data leaves your machine.
*   **Network**: Glupe makes outbound connections to:
    *   LLM Providers (if configured for cloud).
    *   GlupeHub (if using `push`/`pull` commands).